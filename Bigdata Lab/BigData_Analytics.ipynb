{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.MapReduce"
      ],
      "metadata": {
        "id": "9xc7Y43jQ1vl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-aTULyEQuuK",
        "outputId": "933b2962-b0ae-4c48-a420-74cd58abe50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello: 2\n",
            "world: 2\n",
            "this: 1\n",
            "is: 2\n",
            "a: 2\n",
            "simple: 1\n",
            "example: 1\n",
            "program: 1\n",
            "mapreduce: 1\n",
            "powerful: 1\n",
            "technique: 1\n",
            "for: 1\n",
            "data: 1\n",
            "processing: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Sample input data (you can replace this with your own text data)\n",
        "text_data = [\n",
        "    \"Hello, world!\",\n",
        "    \"This is a simple example program.\",\n",
        "    \"MapReduce is a powerful technique for data processing.\",\n",
        "    \"Hello, world!\",\n",
        "]\n",
        "\n",
        "# Define the Mapper function\n",
        "def mapper(text):\n",
        "    words = text.split()\n",
        "    word_count = defaultdict(int)\n",
        "    for word in words:\n",
        "        # Convert words to lowercase and remove punctuation\n",
        "        word = word.strip('.,!?:;\\'\"()[]{}').lower()\n",
        "        if word:\n",
        "            word_count[word] += 1\n",
        "    for word, count in word_count.items():\n",
        "        yield (word, count)\n",
        "\n",
        "# Define the Reducer function\n",
        "def reducer(word, counts):\n",
        "    yield (word, sum(counts))\n",
        "\n",
        "# Map step\n",
        "word_counts = defaultdict(list)\n",
        "for text in text_data:\n",
        "    for word, count in mapper(text):\n",
        "        word_counts[word].append(count)\n",
        "\n",
        "# Reduce step\n",
        "for word, counts in word_counts.items():\n",
        "    total_count = sum(counts)\n",
        "    for result in reducer(word, counts):\n",
        "        print(f\"{result[0]}: {result[1]}\")\n",
        "\n"
      ]
    }
  ]
}